{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fc562",
   "metadata": {},
   "source": [
    "### Rotten Tomatoes Sentiment Analysis with GPT-2 and PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42707c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets==\"3.2.0\" transformers[torch] scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Prepare Dataset\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Load Rotten Tomatoes dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c956858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Class Balance Analysis\n",
    "def check_class_balance(dataset_split, split_name):\n",
    "    \"\"\"Analyze label distribution in a specific dataset split\"\"\"\n",
    "    labels = dataset_split[\"label\"]\n",
    "    class_counts = {\n",
    "        0: labels.count(0),\n",
    "        1: labels.count(1)\n",
    "    }\n",
    "    total = len(labels)\n",
    "    \n",
    "    print(f\"\\n=== Class Distribution - {split_name} ===\")\n",
    "    print(f\"Negative samples: {class_counts[0]} ({class_counts[0]/total:.2%})\")\n",
    "    print(f\"Positive samples: {class_counts[1]} ({class_counts[1]/total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d0507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class Distribution - Training Set ===\n",
      "Negative samples: 4265 (50.00%)\n",
      "Positive samples: 4265 (50.00%)\n",
      "\n",
      "=== Class Distribution - Validation Set ===\n",
      "Negative samples: 533 (50.00%)\n",
      "Positive samples: 533 (50.00%)\n",
      "\n",
      "=== Class Distribution - Test Set ===\n",
      "Negative samples: 533 (50.00%)\n",
      "Positive samples: 533 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "# Check balance for all splits\n",
    "check_class_balance(dataset[\"train\"], \"Training Set\")\n",
    "check_class_balance(dataset[\"validation\"], \"Validation Set\")\n",
    "check_class_balance(dataset[\"test\"], \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e80bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 3. Initialize Model and Tokenizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498ccd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model with sequence classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'gpt2',\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    ").to(device).eval()  # Keep in evaluation mode for baseline assessment\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed83d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dataset Preprocessing and Tokenization\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Batch processing function for tokenization\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Tokenize all splits\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1fecc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets splits\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "validation_dataset = tokenized_datasets[\"validation\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]\n",
    "eval_dataset = concatenate_datasets([validation_dataset, test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5488e0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Tokenization:\n",
      "\n",
      "=== Class Distribution - Training Set ===\n",
      "Negative samples: 4265 (50.00%)\n",
      "Positive samples: 4265 (50.00%)\n",
      "\n",
      "=== Class Distribution - Combined Evaluation Set ===\n",
      "Negative samples: 1066 (50.00%)\n",
      "Positive samples: 1066 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "# Verify post-tokenization balance\n",
    "print(\"\\nAfter Tokenization:\")\n",
    "check_class_balance(train_dataset, \"Training Set\")\n",
    "check_class_balance(eval_dataset, \"Combined Evaluation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1267a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Baseline Model Evaluation\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate comprehensive classification metrics\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": (predictions == labels).mean(),\n",
    "        \"f1_macro\": f1_score(labels, predictions, average='macro'),\n",
    "        \"precision_macro\": precision_score(labels, predictions, average='macro'),\n",
    "        \"recall_macro\": recall_score(labels, predictions, average='macro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd442771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Create data collator with correct tokenizer reference\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=\"longest\",\n",
    "    max_length=128,\n",
    "    pad_to_multiple_of=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416f7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure evaluation trainer\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./baseline\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        disable_tqdm=True\n",
    "    ),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b1db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Baseline Model...\n",
      "{'eval_loss': 0.8969319462776184, 'eval_accuracy': 0.49906191369606, 'eval_f1_macro': 0.34577175037352026, 'eval_precision_macro': 0.4850557954354287, 'eval_recall_macro': 0.49906191369606, 'eval_runtime': 18.2571, 'eval_samples_per_second': 116.777, 'eval_steps_per_second': 7.34}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline performance\n",
    "print(\"\\nEvaluating Baseline Model...\")\n",
    "baseline_metrics = eval_trainer.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc3ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def evaluate_and_show_samples(trainer, dataset, quantity=10, random_seed=42):\n",
    "    \"\"\"Avalia um dataset, cria um DataFrame e exibe amostra aleatória.\"\"\"\n",
    "    \n",
    "    # Realiza as previsões\n",
    "    results = trainer.predict(dataset)\n",
    "\n",
    "    # Cria o DataFrame com textos, previsões e rótulos reais\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": dataset[\"text\"],  # Alternativa sem loop\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    })\n",
    "\n",
    "    # Define exibição completa do texto no Pandas\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "    # Retorna uma amostra aleatória do DataFrame\n",
    "    return df.sample(n=quantity, random_state=random_seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c9ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results from model before PAFT:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool gadgets and creatures keep this fresh . not as good as the original , but what is . . .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an awful movie that will only satisfy the most emotionally malleable of filmgoers .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. . . you can be forgiven for realizing that you've spent the past 20 minutes looking at your watch and waiting for frida to just die already .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>though uniformly well acted , especially by young ballesta and galan ( a first-time actor ) , writer/director achero manas's film is schematic and obvious .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely ( and unintentionally ) terrifying .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shanghai ghetto , much stranger than any fiction , brings this unknown slice of history affectingly to life .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>while hoffman's performance is great , the subject matter goes nowhere .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>as a science fiction movie , \" minority report \" astounds .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what one is left with , even after the most awful acts are committed , is an overwhelming sadness that feels as if it has made its way into your very bloodstream .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  text  \\\n",
       "0                                                                         cool gadgets and creatures keep this fresh . not as good as the original , but what is . . .   \n",
       "1                                                                                  an awful movie that will only satisfy the most emotionally malleable of filmgoers .   \n",
       "2                      . . . you can be forgiven for realizing that you've spent the past 20 minutes looking at your watch and waiting for frida to just die already .   \n",
       "3         though uniformly well acted , especially by young ballesta and galan ( a first-time actor ) , writer/director achero manas's film is schematic and obvious .   \n",
       "4                                                                                                                      absolutely ( and unintentionally ) terrifying .   \n",
       "5                                                        shanghai ghetto , much stranger than any fiction , brings this unknown slice of history affectingly to life .   \n",
       "6                                                                                             while hoffman's performance is great , the subject matter goes nowhere .   \n",
       "7                 works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .   \n",
       "8                                                                                                          as a science fiction movie , \" minority report \" astounds .   \n",
       "9  what one is left with , even after the most awful acts are committed , is an overwhelming sadness that feels as if it has made its way into your very bloodstream .   \n",
       "\n",
       "   predictions  labels  \n",
       "0            1       1  \n",
       "1            1       0  \n",
       "2            1       0  \n",
       "3            1       0  \n",
       "4            1       0  \n",
       "5            1       1  \n",
       "6            1       0  \n",
       "7            1       1  \n",
       "8            1       1  \n",
       "9            1       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nResults from model before PAFT:\")\n",
    "df_before = evaluate_and_show_samples(eval_trainer, eval_dataset, quantity=10)\n",
    "df_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc373f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PEFT Configuration and Training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Freeze base model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Configure LoRA adapter\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=['c_attn', 'c_proj'],\n",
    "    bias=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 814,080 || all params: 125,253,888 || trainable%: 0.6499438963523432\n"
     ]
    }
   ],
   "source": [
    "# Create PEFT model\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./peft_results\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PEFT trainer\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a747702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting PEFT Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [534/534 03:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>0.329269</td>\n",
       "      <td>0.856004</td>\n",
       "      <td>0.855987</td>\n",
       "      <td>0.856170</td>\n",
       "      <td>0.856004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./peft_results/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=534, training_loss=0.46670656213153167, metrics={'train_runtime': 193.8923, 'train_samples_per_second': 43.994, 'train_steps_per_second': 2.754, 'total_flos': 562538328883200.0, 'train_loss': 0.46670656213153167, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute PEFT training\n",
    "print(\"\\nStarting PEFT Training...\")\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e872f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating PEFT Model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Final Evaluation and Comparison\n",
    "print(\"\\nEvaluating PEFT Model...\")\n",
    "peft_metrics = peft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b684f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performance Comparison ===\n",
      "Metric               | Baseline   | PEFT      \n",
      "---------------------------------------------\n",
      "EVAL_LOSS            | 0.8969     | 0.3293    \n",
      "EVAL_ACCURACY        | 0.4991     | 0.8560    \n",
      "EVAL_F1_MACRO        | 0.3458     | 0.8560    \n",
      "EVAL_PRECISION_MACRO | 0.4851     | 0.8562    \n",
      "EVAL_RECALL_MACRO    | 0.4991     | 0.8560    \n",
      "EVAL_RUNTIME         | 18.2571    | 19.3549   \n",
      "EVAL_SAMPLES_PER_SECOND | 116.7770   | 110.1530  \n",
      "EVAL_STEPS_PER_SECOND | 7.3400     | 6.9230    \n"
     ]
    }
   ],
   "source": [
    "# Performance comparison table\n",
    "print(\"\\n=== Performance Comparison ===\")\n",
    "print(f\"{'Metric':<20} | {'Baseline':<10} | {'PEFT':<10}\")\n",
    "print(\"-\" * 45)\n",
    "for key in baseline_metrics:\n",
    "    if key in peft_metrics:\n",
    "        base_val = f\"{baseline_metrics[key]:.4f}\" if isinstance(baseline_metrics[key], float) else str(baseline_metrics[key])\n",
    "        peft_val = f\"{peft_metrics[key]:.4f}\" if isinstance(peft_metrics[key], float) else str(peft_metrics[key])\n",
    "        print(f\"{key.upper():<20} | {base_val:<10} | {peft_val:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcf07959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/gpt2-rotten-tomatoes-lora/tokenizer_config.json',\n",
       " './model/gpt2-rotten-tomatoes-lora/special_tokens_map.json',\n",
       " './model/gpt2-rotten-tomatoes-lora/vocab.json',\n",
       " './model/gpt2-rotten-tomatoes-lora/merges.txt',\n",
       " './model/gpt2-rotten-tomatoes-lora/added_tokens.json',\n",
       " './model/gpt2-rotten-tomatoes-lora/tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.save_pretrained(\"./model/gpt2-rotten-tomatoes-lora\")\n",
    "tokenizer.save_pretrained(\"./model/gpt2-rotten-tomatoes-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecd779d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results from model after PAFT:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cool gadgets and creatures keep this fresh . not as good as the original , but what is . . .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an awful movie that will only satisfy the most emotionally malleable of filmgoers .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. . . you can be forgiven for realizing that you've spent the past 20 minutes looking at your watch and waiting for frida to just die already .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>though uniformly well acted , especially by young ballesta and galan ( a first-time actor ) , writer/director achero manas's film is schematic and obvious .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely ( and unintentionally ) terrifying .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shanghai ghetto , much stranger than any fiction , brings this unknown slice of history affectingly to life .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>while hoffman's performance is great , the subject matter goes nowhere .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>as a science fiction movie , \" minority report \" astounds .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what one is left with , even after the most awful acts are committed , is an overwhelming sadness that feels as if it has made its way into your very bloodstream .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  text  \\\n",
       "0                                                                         cool gadgets and creatures keep this fresh . not as good as the original , but what is . . .   \n",
       "1                                                                                  an awful movie that will only satisfy the most emotionally malleable of filmgoers .   \n",
       "2                      . . . you can be forgiven for realizing that you've spent the past 20 minutes looking at your watch and waiting for frida to just die already .   \n",
       "3         though uniformly well acted , especially by young ballesta and galan ( a first-time actor ) , writer/director achero manas's film is schematic and obvious .   \n",
       "4                                                                                                                      absolutely ( and unintentionally ) terrifying .   \n",
       "5                                                        shanghai ghetto , much stranger than any fiction , brings this unknown slice of history affectingly to life .   \n",
       "6                                                                                             while hoffman's performance is great , the subject matter goes nowhere .   \n",
       "7                 works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .   \n",
       "8                                                                                                          as a science fiction movie , \" minority report \" astounds .   \n",
       "9  what one is left with , even after the most awful acts are committed , is an overwhelming sadness that feels as if it has made its way into your very bloodstream .   \n",
       "\n",
       "   predictions  labels  \n",
       "0            1       1  \n",
       "1            0       0  \n",
       "2            0       0  \n",
       "3            1       0  \n",
       "4            1       0  \n",
       "5            1       1  \n",
       "6            0       0  \n",
       "7            0       1  \n",
       "8            1       1  \n",
       "9            1       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nResults from model after PAFT:\")\n",
    "df_after = evaluate_and_show_samples(peft_trainer, eval_dataset, quantity=10)\n",
    "df_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load saved PEFT model for inference\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "peft_loaded = AutoPeftModelForSequenceClassification.from_pretrained(\"./model/gpt2-rotten-tomatoes-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inference function for PEFT model (generate text)\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move para GPU se disponível\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)  # Executa a inferência\n",
    "\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1).item()  # Obtém a classe prevista (0 ou 1)\n",
    "    return model.config.id2label[prediction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample reviews\n",
    "test_samples = [\n",
    "    \"A masterpiece of cinematic excellence!\",\n",
    "    \"A tedious and poorly executed film.\",\n",
    "    \"The actors delivered mediocre performances in a weak script.\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "- A masterpiece of cinematic excellence!\n",
      "  Prediction: POSITIVE\n",
      "\n",
      "- A tedious and poorly executed film.\n",
      "  Prediction: NEGATIVE\n",
      "\n",
      "- The actors delivered mediocre performances in a weak script.\n",
      "  Prediction: NEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Predictions:\")\n",
    "for sample in test_samples:\n",
    "    prediction = predict_sentiment(sample)  # Chama a função corrigida\n",
    "    print(f\"- {sample}\")\n",
    "    print(f\"  Prediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ccf0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive review (likely misclassified as negative)\n",
    "pos_review = \"Everything about this film feels off—the pacing is slow, the dialogue awkward, and yet, by the end, it’s a stunning masterpiece that lingers in your mind.\"\n",
    "\n",
    "# Negative review (likely misclassified as positive)\n",
    "neg_review = \"The film is beautifully shot and well-acted, but beneath its polished surface, it lacks any real heart or emotional depth.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03e0ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for positive review: POSITIVE\n",
      "Classification for negative review: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification for positive review: {predict_sentiment(pos_review)}\")\n",
    "print(f\"Classification for negative review: {predict_sentiment(neg_review)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a039c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 814,080 || all params: 125,253,888 || trainable%: 0.6499438963523432\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5579e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,072 || all params: 125,253,888 || trainable%: 0.002452618476801295\n"
     ]
    }
   ],
   "source": [
    "peft_loaded.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adeacb6",
   "metadata": {},
   "source": [
    "## 📊 Conclusion: Performance Comparison  \n",
    "\n",
    "The results show a **significant improvement** in model performance after applying **PEFT (Parameter Efficient Fine-Tuning)**.  \n",
    "\n",
    "### 🔹 **Key Improvements**  \n",
    "- **Eval Loss** decreased from `0.7657` to `0.3371`, indicating that the fine-tuned model makes fewer errors.  \n",
    "- **Accuracy** increased from `50.28%` to `85.79%`, showing that the model has learned the data patterns much better.  \n",
    "- **F1-Score Macro** improved from `0.3460` to `0.8578`, proving that the model now balances precision and recall effectively.  \n",
    "- **Precision and Recall** also increased from around `50% - 56%` to `85.8%`, confirming the robustness of the fine-tuned model.  \n",
    "\n",
    "### 🔸 **Trade-offs**  \n",
    "- The evaluation time increased **slightly** (`18.33s → 19.34s`), likely due to the additional computations from PEFT.  \n",
    "- The sampling rate decreased slightly (`116.29 samples/s → 110.22 samples/s`), but this drop is negligible compared to the significant improvement in prediction quality.  \n",
    "\n",
    "### ✅ **Final Conclusion**  \n",
    "Using **PEFT** resulted in a **much more accurate and efficient model**, with a **better balance between precision and recall**. Despite the minor increase in runtime, the performance gains make this approach highly beneficial. 🚀  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
